# Imports
import sys
import os
import argparse
import pandas as pd
import openmatrix as omx
import sqlite3
from itertools import product

# Import modules from core code (two levels up) by setting path
sys.path.append(os.path.join(os.path.dirname(__file__), '..', '..', 'metamodel_py'))
import rdr_AESingleRun
import rdr_setup
import rdr_supporting
import rdr_CompileAE

VERSION_NUMBER = "2024.1"
VERSION_DATE = "5/22/2024"
# ---------------------------------------------------------------------------------------------------
# The following code processes an existing scenario configuration to automatically
# generate the outputs of all of the AequilibraE base year runs into one consolidated CSV file
# Users need to create this file before running a scenario, based on predefined inputs from the scenario configuration
# ---------------------------------------------------------------------------------------------------


def main():

    # PARSE ARGS
    # ----------------------------------------------------------------------------------------------

    program_description = 'Resilience Disaster Recovery Base Year Run Helper Tool: ' \
                          + VERSION_NUMBER + ", (" + VERSION_DATE + ")"

    help_text = """
    The command-line input expected for this script is as follows:

    TheFilePathOfThisScript ConfigFilePath
    """

    parser = argparse.ArgumentParser(description=program_description, usage=help_text)

    parser.add_argument("config_file", help="The full path to the XML Scenario", type=str)

    if len(sys.argv) == 2:
        args = parser.parse_args()
    else:
        parser.print_help()
        sys.exit()

    # ---------------------------------------------------------------------------------------------------
    # SETUP
    error_list, cfg = rdr_setup.read_config_file(args.config_file, 'config')

    # Output of this helper tool along w/ the intermediate outputs required to create it are put in the scenario's input dir
    input_dir = cfg['input_dir']

    # Logs and some of the scenario's intermediate outputs are put in the scenario's output dir
    output_dir = cfg['output_dir']

    # Set up logging
    logger = rdr_supporting.create_loggers(output_dir, 'baseyear_run', cfg)
    if len(error_list) > 0:
        logger.error('\n'.join(error_list))
        raise Exception('{} errors found in config and/or setup file(s). Check log file in {} for list of errors.'.format(len(error_list)), output_dir)

    logger.info("Starting base year run...")

    # Set up output file name
    # Exact output file name depends on whether it is a shortest path or routing run (set in scenario's configuration)
    if cfg['aeq_run_type'] == 'SP':
        base_year_output_csv = os.path.join(input_dir, 'Metamodel_scenarios_SP_baseyear.csv')
    elif cfg['aeq_run_type'] == 'RT':
        base_year_output_csv = os.path.join(input_dir, 'Metamodel_scenarios_RT_baseyear.csv')

    # Check if output file already exists
    if os.path.exists(base_year_output_csv):
        logger.error("Base year output file from AequilibraE: {} already exists. ".format(base_year_output_csv) +
                     "Please delete or move this file before running this tool")
        raise Exception("Base year output file from AequilibraE: {} already exists. ".format(base_year_output_csv) +
                        "Please delete or move this file before running this tool")

    # ---------------------------------------------------------------------------------------------------
    # MAIN
    # Read in the different hazards and recoveries using the UncertaintyParameters sheet of Model_Parameters.xlsx file.
    # This sheet needs to be generated by the user before this tool is run.

    # Build out the base year scenario space (this is based on code in rdr_LHS.py but is customized for base year runs)
    model_params_file = os.path.join(input_dir, 'Model_Parameters.xlsx')

    if not os.path.exists(model_params_file):
        logger.error("MODEL PARAMETERS FILE ERROR: {} could not be found".format(model_params_file))
        raise Exception("MODEL PARAMETERS FILE ERROR: {} could not be found".format(model_params_file))

    # Check that hazards are sufficient for the scenario space
    is_covered = check_hazards_coverage(model_params_file, input_dir, logger)
    if is_covered == 0:
        logger.error(("INSUFFICIENT HAZARD INPUT DATA ERROR: missing input files for " +
                      "scenario space defined by {}".format(model_params_file)))
        raise Exception(("INSUFFICIENT HAZARD INPUT DATA ERROR: missing input files for " +
                         "scenario space defined by {}".format(model_params_file)))

    model_params = pd.read_excel(model_params_file, sheet_name='UncertaintyParameters',
                                 converters={'Hazard Events': str, 'Recovery Stages': str,
                                             'Economic Scenarios': str, 'Trip Loss Elasticities': float,
                                             'Project Groups': str})

    hazard = set(model_params['Hazard Events'].dropna().tolist())
    logger.config("List of hazards: \t{}".format(', '.join(str(e) for e in hazard)))
    recovery = set(model_params['Recovery Stages'].dropna().tolist())
    logger.config("List of recovery stages: \t{}".format(', '.join(str(e) for e in recovery)))

    product1 = pd.DataFrame(list(product(hazard, recovery)),
                            columns=['hazard', 'recovery'])

    logger.debug("Size of full scenario space: {}".format(product1.shape))

    # ---------------------------------------------------------------------------------------------------
    # SETUP SQLITE nodes data
    setup_sql_nodes(input_dir, logger)

    # ---------------------------------------------------------------------------------------------------
    # AEQ SINGLE RUNS
    # Creating dictionary for settings for Aequilibrae
    for index, row in product1.iterrows():
        hazard = row['hazard']
        recovery = row['recovery']

        run_params = {}
        run_params['socio'] = 'baseyear'  # always baseyear for base year runs
        run_params['projgroup'] = ''  # always empty string for base year runs
        run_params['resil'] = 'no'  # always no for base year runs
        run_params['elasticity'] = -1  # always -1 for base year runs
        run_params['hazard'] = str(hazard)  # examples: strings containing storm surge + sea-level rise details
        run_params['recovery'] = str(recovery)  # format: strings like X ft of exposure to subtract for recovery stage
        run_params['run_minieq'] = cfg['run_minieq']  # possibilities: 1 or 0
        run_params['matrix_name'] = 'matrix'  # always run AequilibraE for the default 'matrix'

        rdr_AESingleRun.run_AESingleRun(run_params, input_dir, output_dir, cfg, logger)

        # run AequilibraE a second time if a 'nocar' trip table exists
        mtx_fldr = 'matrices'
        demand_file = os.path.join(input_dir, 'AEMaster', mtx_fldr, run_params['socio'] + '_demand_summed.omx')
        if not os.path.exists(demand_file):
            logger.error("DEMAND OMX FILE ERROR: {} could not be found".format(demand_file))
            raise Exception("DEMAND OMX FILE ERROR: {} could not be found".format(demand_file))
        f = omx.open_file(demand_file)
        if 'nocar' in f.list_matrices():
            f.close()
            run_params['matrix_name'] = 'nocar'

            rdr_AESingleRun.run_AESingleRun(run_params, input_dir, output_dir, cfg, logger)
        else:
            f.close()

    # An AequilibraE run produces one line in the NetSkim CSV
    # This row has to be pulled out of the output file and compiled into the output CSV
    # Order of output doesn't matter but the column headers are required

    # ---------------------------------------------------------------------------------------------------
    # Compiling all the base year disrupted single runs using rdr_CompileAE
    rdr_CompileAE.main(input_dir, output_dir, cfg, logger, True)

    # Further process the above generated CSV to limit to just "Disrupt" runs associated with the run type (SP or RT)
    df = pd.read_csv(os.path.join(input_dir, 'Metamodel_scenarios_baseyear.csv'))
    df = df.loc[df['Type'] == 'Disrupt'].copy()
    df = df.loc[df['SP/RT'] == cfg['aeq_run_type']].copy()

    # Drop unnecessary fields
    df = df.drop(columns=['Type', 'SP/RT', 'Scenario']).copy()

    # Copy the filtered df to the final output CSV
    df.to_csv(base_year_output_csv, index=False)

    # Delete unfiltered CSV
    os.remove(os.path.join(input_dir, 'Metamodel_scenarios_baseyear.csv'))

    logger.info("Finished base year run")


# ---------------------------------------------------------------------------------------------------
def check_hazards_coverage(model_params_file, input_folder, logger):
    logger.info("Start: check_hazards_coverage")
    is_covered = 1
    model_params = pd.read_excel(model_params_file, sheet_name='UncertaintyParameters',
                                 usecols=['Hazard Events'],
                                 converters={'Hazard Events': str})
    hazard_events = pd.read_excel(model_params_file, sheet_name='Hazards',
                                  usecols=['Hazard Event', 'Filename'],
                                  converters={'Hazard Event': str, 'Filename': str})

    # Read in column 'Hazard Events'
    hazard = set(model_params['Hazard Events'].dropna().tolist())

    hazards_list = pd.merge(pd.DataFrame(hazard, columns=['Hazard Event']),
                            hazard_events, how='left', on='Hazard Event')
    for index, row in hazards_list.iterrows():
        filename = os.path.join(input_folder, 'Hazards', str(row['Filename']) + '.csv')
        if not os.path.exists(filename):
            is_covered = 0
            logger.error("Missing input file {}".format(filename))

    logger.info("Finished: check_hazards_coverage")
    return is_covered


# ---------------------------------------------------------------------------------------------------
def setup_sql_nodes(input_dir, logger):
    # Aequilibrae requires a SQLite database to be setup first--this code is copied from rdr_RunAE.py
    # Set up AEMaster SQLite database with node information
    logger.info("importing node input file into SQLite database")
    node_file = os.path.join(input_dir, 'Networks', 'node.csv')
    network_db = os.path.join(input_dir, 'AEMaster', 'project_database.sqlite')
    if not os.path.exists(node_file):
        logger.error("NODE FILE ERROR: {} could not be found".format(node_file))
        raise Exception("NODE FILE ERROR: {} could not be found".format(node_file))
    elif not os.path.exists(network_db):
        logger.error("SQLITE DB ERROR: {} could not be found".format(network_db))
        raise Exception("SQLITE DB ERROR: {} could not be found".format(network_db))
    else:
        df_node = pd.read_csv(node_file, usecols=['node_id', 'x_coord', 'y_coord', 'node_type'],
                              converters={'node_id': str, 'x_coord': float, 'y_coord': float, 'node_type': str})

        with sqlite3.connect(network_db) as db_con:
            # Use to_sql to import df_node as table named GMNS_node
            # NOTE for to_sql: "Legacy support is provided for sqlite3.Connection objects."
            df_node.to_sql('GMNS_node', db_con, if_exists='replace', index=False)
            db_cur = db_con.cursor()

            # Delete existing nodes table
            sql1 = "delete from nodes;"
            db_cur.execute(sql1)
            # Insert node data into nodes table
            sql2 = """insert into nodes (ogc_fid, node_id, x, y, is_centroid)
                    select node_id, node_id, x_coord, y_coord, case node_type when 'centroid' then 1 else 0 end
                    from GMNS_node
                    order by node_id asc;"""
            db_cur.execute(sql2)


# ---------------------------------------------------------------------------------------------------
if __name__ == "__main__":
    main()
